{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:35:21.351317Z",
     "start_time": "2019-08-02T10:35:21.320643Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:28:20.138694Z",
     "start_time": "2019-08-02T10:28:19.685839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points :  3321\n",
      "number of features :  4\n",
      "Features :  ['ID' 'Gene' 'Variation' 'Class']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Training/training_variants')\n",
    "print('number of data points : ', data.shape[0])\n",
    "print('number of features : ', data.shape[1])\n",
    "print('Features : ', data.columns.values)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data has 3321 Data points with 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:28:23.762843Z",
     "start_time": "2019-08-02T10:28:21.747727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points :  3321\n",
      "Number of features :  2\n",
      "Features :  ['ID' 'TEXT']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT\n",
       "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
       "1   1   Abstract Background  Non-small cell lung canc...\n",
       "2   2   Abstract Background  Non-small cell lung canc...\n",
       "3   3  Recent evidence has demonstrated that acquired...\n",
       "4   4  Oncogenic mutations in the monomeric Casitas B..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text = pd.read_csv('Training/training_text', sep='\\|\\|', engine= 'python', names=['ID', 'TEXT'], skiprows = 1)\n",
    "print('Number of data points : ', data_text.shape[0])\n",
    "print('Number of features : ', data_text.shape[1])\n",
    "print('Features : ', data_text.columns.values)\n",
    "data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:28:28.076267Z",
     "start_time": "2019-08-02T10:28:23.872193Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:28:28.123080Z",
     "start_time": "2019-08-02T10:28:28.076267Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def nlp_preprocessing(total_text, index, column):\n",
    "    if type(total_text) is not int:                  #Checks if its a int or not\n",
    "        string = \"\"\n",
    "        #replace every special character with space\n",
    "        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n",
    "        #replace with multiple spaces with single space\n",
    "        total_text = re.sub('\\s+', ' ', total_text)\n",
    "        #convert all char to lower case\n",
    "        total_text = total_text.lower()\n",
    "        \n",
    "        for word in total_text.split():\n",
    "            if not word in stop_words:\n",
    "                string += word + ' '\n",
    "                \n",
    "        data_text[column][index] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:28:29.059870Z",
     "start_time": "2019-08-02T10:28:29.044627Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:29:39.848463Z",
     "start_time": "2019-08-02T10:28:30.090840Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is no description for id : 1109\n",
      "there is no description for id : 1277\n",
      "there is no description for id : 1407\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7f9d6372f975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TEXT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mnlp_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TEXT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TEXT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"there is no description for id :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-dc2ed10df9b1>\u001b[0m in \u001b[0;36mnlp_preprocessing\u001b[1;34m(total_text, index, column)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mstring\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mdata_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "for index, row in data_text.iterrows():\n",
    "    if type(row[\"TEXT\"]) is str:\n",
    "        nlp_preprocessing(row['TEXT'], index, 'TEXT')\n",
    "    else:\n",
    "        print(\"there is no description for id :\", index)\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:29:52.348039Z",
     "start_time": "2019-08-02T10:29:52.301137Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.merge(data, data_text, on=\"ID\", how=\"left\")\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:29:55.027756Z",
     "start_time": "2019-08-02T10:29:54.996571Z"
    }
   },
   "outputs": [],
   "source": [
    "result[result.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:29:55.717690Z",
     "start_time": "2019-08-02T10:29:55.670313Z"
    }
   },
   "outputs": [],
   "source": [
    "result.loc[result['TEXT'].isnull(), 'TEXT'] = result['Variation'] + result['Gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:29:57.150817Z",
     "start_time": "2019-08-02T10:29:57.119574Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result[result['ID']==1277]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing the dataset into testing and training sets and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:29:59.421547Z",
     "start_time": "2019-08-02T10:29:59.390304Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = result['Class'].values\n",
    "\n",
    "#replacing spaces between the words in Gene column with '_'\n",
    "result.Gene = result.Gene.str.replace('\\s+', '_')\n",
    "\n",
    "#replacing spaces between the words in Variation column with '_'\n",
    "result.Variation = result.Variation.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:30:01.749126Z",
     "start_time": "2019-08-02T10:30:01.717965Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:30:03.047137Z",
     "start_time": "2019-08-02T10:30:03.015894Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting into train test\n",
    "X_train, test_df, y_train, y_test = train_test_split(result, y_true, stratify = y_true, test_size=0.2)\n",
    "\n",
    "#splitting train into train and cross validation\n",
    "train_df, cv_df, y_train, y_cv = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:30:04.690698Z",
     "start_time": "2019-08-02T10:30:04.675514Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_df.shape[0]) #data points in train set\n",
    "print(test_df.shape[0])  #data points in test set\n",
    "print(cv_df.shape[0])    #data points in cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:30:06.879007Z",
     "start_time": "2019-08-02T10:30:06.847801Z"
    }
   },
   "outputs": [],
   "source": [
    "train_class_distribution = train_df['Class'].value_counts().sort_index()\n",
    "test_class_distribution = test_df['Class'].value_counts().sort_index()\n",
    "cv_class_distribution = cv_df['Class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:30:08.284928Z",
     "start_time": "2019-08-02T10:30:08.254269Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:30:09.097274Z",
     "start_time": "2019-08-02T10:30:09.065995Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:34:41.144716Z",
     "start_time": "2019-08-02T10:34:41.113470Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cv_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:36:47.214257Z",
     "start_time": "2019-08-02T10:36:47.198634Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "style.use('fivethirtyeight') or plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:36:47.792262Z",
     "start_time": "2019-08-02T10:36:47.526749Z"
    }
   },
   "outputs": [],
   "source": [
    "my_colors = 'rgbkmyc'\n",
    "train_class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per class')\n",
    "plt.title('Distribution')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i+1, ':', train_class_distribution.values[i], '[', np.round((train_class_distribution.values[i]/train_df.shape[0]*100), 2), '%]' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:36:50.683422Z",
     "start_time": "2019-08-02T10:36:50.496519Z"
    }
   },
   "outputs": [],
   "source": [
    "my_colors = 'rgbkmyc'\n",
    "train_class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per class')\n",
    "plt.title('Distribution')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi = np.argsort(-test_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i+1, ':', test_class_distribution.values[i], '[', np.round((test_class_distribution.values[i]/test_df.shape[0]*100), 2), '%]' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T10:36:51.323910Z",
     "start_time": "2019-08-02T10:36:51.137028Z"
    }
   },
   "outputs": [],
   "source": [
    "my_colors = 'rgbkmyc'\n",
    "train_class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per class')\n",
    "plt.title('Distribution')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi = np.argsort(-cv_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i+1, ':', train_class_distribution.values[i], '[', np.round((cv_class_distribution.values[i]/cv_df.shape[0]*100), 2), '%]' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using a random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    \n",
    "    #divide each element of the confusion matrix with the sum of elements in that column\n",
    "    A = (((C.T)/(C.sum(axis=1))).T)\n",
    "    \n",
    "    #divide each element of the confusion matrix with the sum of elements in that row\n",
    "    B = ((C/C.sum(axis=0)))\n",
    "    labels = [1,2,3,4,5,6,7,8,9]\n",
    "    \n",
    "    print(\"-\"*30, \"Confusion matrix\", \"-\"*30)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(C, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*20, \"Precision matrix (Columm Sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(B, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*20, \"Recall matrix (Row sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(A, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape[0])\n",
    "print(cv_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "import sys\n",
    "sys.setrecursionlimit(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_len = test_df.shape[0]\n",
    "cv_data_len = cv_df.shape[0]\n",
    "\n",
    "cv_predicted_y = np.zeros((cv_data_len,9))\n",
    "for i in range(cv_data_len):\n",
    "    rand_probs= np.random.rand(1,9)\n",
    "    cv_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Cross Validation Data using Random Model\",log_loss(y_cv,cv_predicted_y, eps=1e-15))\n",
    "\n",
    "#test set error\n",
    "test_predicted_y = np.zeros((test_data_len, 9))\n",
    "for i in range(test_data_len):\n",
    "    rand_probs = np.random.rand(1,9)\n",
    "    test_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on test Data using Random Model\",log_loss(y_cv,cv_predicted_y, eps=1e-15))\n",
    "\n",
    "predicted_y = np.argmax(test_predicted_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genes = train_df['Gene'].value_counts()\n",
    "print('Number of unique genes: ', unique_genes.shape[0])\n",
    "print(unique_genes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sum(unique_genes.values)\n",
    "h = unique_genes.values/s\n",
    "plt.plot(h, label='Histogram of genes')\n",
    "plt.xlabel('Index of a Gene')\n",
    "plt.ylabel('Number of Occurances')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.cumsum(h)\n",
    "plt.plot(c, label='Cumulative distribution')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gv_fea_dict(alpha, feature, df):\n",
    "    value_count = train_df[feature].value_counts()  #Gives the count of eacg gene and variation in the dataframe\n",
    "     \n",
    "    gv_dict = dict()   #this dict will contain 9 probabilities of each gene variation of 9 classes\n",
    "    \n",
    "    for i, denominator in value_count.items():\n",
    "        vec = []    #9 dimensional list containing 9 probabilities of each class for the ith gene\n",
    "        for k in range(1,10):      #9 classes in total, count starts from 1-9\n",
    "            cls_cnt = train_df.loc[(train_df['Class']==k) & (train_df[feature]==i)]\n",
    "                                            #cls_cnt Displays all the class and variation o fthat specigic gene\n",
    "            vec.append((cls_cnt.shape[0] + alpha*10) / (denominator + 90*alpha))\n",
    "            \n",
    "        gv_dict[i] = vec\n",
    "        \n",
    "    return gv_dict\n",
    "\n",
    "\n",
    "def get_gv_feature(alpha, feature, df):\n",
    "    \n",
    "    gv_dict = get_gv_fea_dict(alpha, feature, df)\n",
    "    value_count = train_df[feature].value_counts()\n",
    "    \n",
    "    gv_fea = []          # for every feature values in the given data frame we will check if it is there in the train data then we will add the feature to gv_fea\n",
    "                         # if not we will add [1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9] to gv_fea\n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        if row[feature] in dict(value_count).keys():\n",
    "            gv_fea.append(gv_dict[row[feature]])\n",
    "        else:\n",
    "            gv_fea.append([1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9])\n",
    "    return gv_fea   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizing Gene Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response coding for the Gene feature\n",
    "\n",
    "alpha = 1    #Used for laplace smoothing\n",
    "train_gene_feature_responseCoding = np.array(get_gv_feature(alpha, \"Gene\", train_df))  #train gene feature\n",
    "test_gene_feature_responseCoding = np.array(get_gv_feature(alpha, \"Gene\", test_df))    #test gene feature\n",
    "cv_gene_feature_responseCoding = np.array(get_gv_feature(alpha, \"Gene\", test_df))      #cv gene feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding of Gene Feature\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "gene_vectorizer = CountVectorizer()\n",
    "train_gene_feature_onehotCoding = gene_vectorizer.fit_transform(train_df['Gene'])\n",
    "test_gene_feature_onehotCoding = gene_vectorizer.fit_transform(test_df['Gene'])\n",
    "cv_gene_feature_onehotCoding = gene_vectorizer.fit_transform(cv_df['Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene_feature_responseCoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene_feature_onehotCoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
